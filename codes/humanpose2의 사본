{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"humanpose2의 사본","provenance":[{"file_id":"1VYghjezb_k3EksXQxA7Oh_zKgnSgDCYp","timestamp":1659951352918},{"file_id":"1aZQySEJ8L1laRav3IZU8DzXZSfYWutQn","timestamp":1655983783836}],"collapsed_sections":[],"mount_file_id":"1aZQySEJ8L1laRav3IZU8DzXZSfYWutQn","authorship_tag":"ABX9TyPSHQk9ss4fLaipKcmxyFYF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","assetPath='/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/assets/'\n","dataPath='/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/dataset/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQmlcR7H_pHH","executionInfo":{"status":"ok","timestamp":1659948935131,"user_tz":-540,"elapsed":27405,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"outputId":"bcd104c5-7714-4852-e89f-46cfd98b081c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["labels=['testifying', 'eating spaghetti', 'dribbling basketball',\n","       'playing tennis', 'tap dancing', 'climbing a rope',\n","       'brushing teeth', 'balloon blowing', 'feeding birds',\n","       'skiing (not slalom or crosscountry)', 'dining', 'hurdling',\n","       'javelin throw', 'pushing wheelchair', 'snowkiting',\n","       'gymnastics tumbling', 'petting animal (not cat)',\n","       'biking through snow', 'drinking', 'sword fighting',\n","       'making snowman', 'somersaulting', 'playing harmonica',\n","       'passing American football (not in game)', 'clay pottery making',\n","       'shaving legs', 'golf chipping', 'cooking chicken',\n","       'hurling (sport)', 'yawning', 'shaking hands',\n","       'canoeing or kayaking', 'hula hooping', 'changing oil', 'sailing',\n","       'playing paintball', 'stretching arm', 'snowboarding',\n","       'skipping rope', 'getting a haircut', 'windsurfing',\n","       'golf putting', 'zumba', 'eating watermelon',\n","       'shooting basketball', 'unboxing', 'marching', 'making bed',\n","       'sanding floor', 'flying kite', 'playing poker',\n","       'giving or receiving award', 'pole vault', 'shoveling snow',\n","       'climbing ladder', 'dancing ballet', 'baking cookies',\n","       'cooking egg', 'hitting baseball',\n","       'passing American football (in game)', 'dancing charleston',\n","       'headbanging', 'peeling potatoes', 'drumming fingers',\n","       'smoking hookah', 'archery', 'motorcycling', 'walking the dog',\n","       'shearing sheep', 'welding', 'singing', 'knitting', 'mowing lawn',\n","       'blasting sand', 'swinging legs', 'making jewelry',\n","       'tapping guitar', 'cartwheeling', 'golf driving', 'milking cow',\n","       'punching bag', 'playing accordion', 'ice climbing', 'auctioning',\n","       'drop kicking', 'busking', 'ironing', 'waxing back',\n","       'catching or throwing softball', 'weaving basket',\n","       'getting a tattoo', 'air drumming', 'playing ukulele', 'abseiling',\n","       'playing guitar', 'playing drums', 'carrying baby', 'bandaging',\n","       'playing trumpet', 'springboard diving', 'celebrating',\n","       'tossing coin', 'using remote controller (not gaming)',\n","       'presenting weather forecast', 'ice skating', 'shuffling cards',\n","       'contact juggling', 'smoking', 'jumping into pool', 'barbequing',\n","       'picking fruit', 'tying tie', 'bookbinding',\n","       'riding mechanical bull', 'riding mule', 'playing monopoly',\n","       'squat', 'sharpening pencil', 'playing harp', 'shaking head',\n","       'catching fish', 'shot put', 'kitesurfing', 'spinning poi',\n","       'crawling baby', 'country line dancing', 'cheerleading',\n","       'spray painting', 'arm wrestling', 'roller skating',\n","       'playing bass guitar', 'playing trombone', 'skydiving',\n","       'climbing tree', 'riding elephant', 'snowmobiling', 'vault',\n","       'tai chi', 'trimming trees', 'breakdancing', 'pull ups',\n","       'playing basketball', 'gargling', 'playing bagpipes',\n","       'blowing out candles', 'riding camel', 'grooming horse',\n","       'riding scooter', 'building shed', 'doing nails', 'front raises',\n","       'bending back', 'capoeira', 'using computer', 'washing feet',\n","       'extinguishing fire', 'changing wheel', 'waxing legs',\n","       'playing recorder', 'playing organ', 'waiting in line',\n","       'dodgeball', 'wrapping present', 'sled dog racing', 'pushing car',\n","       'hammer throw', 'whistling', 'faceplanting',\n","       'punching person (boxing)', 'swimming butterfly stroke',\n","       'feeding fish', 'opening present', 'dancing macarena', 'trapezing',\n","       'shining shoes', 'parasailing', 'pumping fist', 'strumming guitar',\n","       'snorkeling', 'eating cake', 'clean and jerk', 'rock climbing',\n","       'dunking basketball', 'playing saxophone', 'watering plants',\n","       'eating doughnuts', 'flipping pancake', 'checking tires',\n","       'eating ice cream', 'folding napkins', 'krumping',\n","       'playing controller', 'water skiing', 'tobogganing',\n","       'playing cello', 'filling eyebrows', 'tossing salad',\n","       'trimming or shaving beard', 'tying bow tie', 'cooking sausages',\n","       'scuba diving', 'swimming backstroke', 'throwing axe',\n","       'cleaning windows', 'parkour', 'long jump',\n","       'snatch weight lifting', 'baby waking up', 'cleaning floor',\n","       'tango dancing', 'bowling', 'surfing crowd', 'using segway',\n","       'playing squash or racquetball', 'robot dancing', 'blowing nose',\n","       'playing didgeridoo', 'kicking field goal', 'playing cards',\n","       'lunge', 'shaving head', 'planting trees', 'diving cliff',\n","       'hockey stop', 'high jump', 'grooming dog', 'reading newspaper',\n","       'salsa dancing', 'taking a shower', 'catching or throwing frisbee',\n","       'riding or walking with horse', 'feeding goats', 'throwing discus',\n","       'bee keeping', 'playing chess', 'massaging back', 'playing piano',\n","       'petting cat', 'stretching leg', 'opening bottle',\n","       'playing violin', 'cleaning gutters', 'slacklining',\n","       'carving pumpkin', 'making sushi', 'bench pressing', 'crying',\n","       'skateboarding', 'reading book', 'high kick', 'digging', 'push up',\n","       'riding unicycle', 'swimming breast stroke', 'counting money',\n","       'sign language interpreting', 'disc golfing', 'finger snapping',\n","       'bungee jumping', 'cutting watermelon', 'cooking on campfire',\n","       'making pizza', 'playing cymbals', 'cleaning shoes',\n","       'breading or breadcrumbing', 'hopscotch', 'massaging feet',\n","       'peeling apples', 'laughing', 'eating carrots', 'blowing glass',\n","       'headbutting', 'sticking tongue out', 'pushing cart',\n","       'playing clarinet', 'cleaning pool', 'triple jump',\n","       'bouncing on trampoline', 'news anchoring', 'clapping',\n","       'tapping pen', 'braiding hair', 'decorating the christmas tree',\n","       'dying hair', 'tasting beer', 'catching or throwing baseball',\n","       'waxing chest', 'riding a bike', 'juggling fire', 'holding snake',\n","       'chopping wood', 'belly dancing', 'writing', 'frying vegetables',\n","       'eating burger', 'playing xylophone', 'driving car',\n","       'kicking soccer ball', 'brushing hair', 'scrambling eggs',\n","       'folding clothes', 'curling hair', 'yoga', 'playing volleyball',\n","       'skiing crosscountry', 'tying knot (not on a tie)', 'slapping',\n","       'spraying', 'washing hands', 'tasting food', 'playing badminton',\n","       'surfing water', 'eating chips', 'recording music',\n","       'waxing eyebrows', 'throwing ball', 'driving tractor', 'side kick',\n","       'playing ice hockey', 'jumpstyle dancing', 'situp', 'jogging',\n","       'running on treadmill', 'juggling soccer ball', 'unloading truck',\n","       'texting', 'cleaning toilet', 'applying cream', 'sweeping floor',\n","       'ski jumping', 'assembling computer', 'playing keyboard',\n","       'arranging flowers', 'ripping paper', 'laying bricks',\n","       'training dog', 'deadlifting', 'sharpening knives', 'beatboxing',\n","       'answering questions', 'egg hunting', 'drinking shots',\n","       'garbage collecting', 'eating hotdog', 'mopping floor',\n","       'bartending', 'grinding meat', 'jetskiing', 'folding paper',\n","       'playing kickball', 'riding mountain bike', 'bending metal',\n","       'juggling balls', 'making a cake', 'hugging', 'fixing hair',\n","       'washing dishes', 'ice fishing', 'exercising arm', 'tickling',\n","       'crossing river', 'playing cricket', 'building cabinet',\n","       'sneezing', 'moving furniture', 'stomping grapes', 'setting table',\n","       'paragliding', 'hoverboarding', 'making a sandwich',\n","       'doing aerobics', 'doing laundry', 'pumping gas',\n","       'cutting pineapple', 'brush painting', 'making tea',\n","       'water sliding', 'drinking beer', 'dancing gangnam style',\n","       'swinging on something', 'swing dancing', 'blowing leaves',\n","       'rock scissors paper', 'shooting goal (soccer)', 'sniffing',\n","       'skiing slalom', 'plastering', 'exercising with an exercise ball',\n","       'cracking neck', 'cutting nails', 'shredding paper',\n","       'playing flute', 'washing hair', 'bobsledding', 'applauding',\n","       \"massaging person's head\", 'kissing', 'massaging legs',\n","       'wrestling', 'drawing']\n","print(len(labels))\n","label_hash={}\n","i=0\n","for label in labels:\n","  label_hash[label]=i\n","  i+=1\n"],"metadata":{"id":"auIcsMKdVrXy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659948951543,"user_tz":-540,"elapsed":982,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"outputId":"3481ce05-9d11-43d1-86da-050e0fbbbbbe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["400\n"]}]},{"cell_type":"code","source":["!pip install torch\n","!pip install av\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIJEXpzCNxpy","executionInfo":{"status":"ok","timestamp":1659948944110,"user_tz":-540,"elapsed":8984,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"outputId":"de8bc18b-b0be-4135-d461-b08c0df55847"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting av\n","  Downloading av-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.2 MB)\n","\u001b[K     |████████████████████████████████| 28.2 MB 1.4 MB/s \n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-9.2.0\n"]}]},{"cell_type":"code","source":["import av\n","print(av.__version__)\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torchvision\n","import torchvision.transforms.functional as F\n","from torchvision.models.detection import keypointrcnn_resnet50_fpn\n","from torchvision.io import read_image\n","from torchvision.transforms.functional import convert_image_dtype\n","from torchvision.io import read_video,read_video_timestamps\n","from torchvision.utils import make_grid\n","from pathlib import Path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JVOnbZ2vl1T","executionInfo":{"status":"ok","timestamp":1659948957639,"user_tz":-540,"elapsed":3947,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"outputId":"2312a5ca-865e-401e-a178-1143ef936a9b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["9.2.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgkFzFAuHXJQ","executionInfo":{"status":"ok","timestamp":1657262876814,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd9ed7f0-dda0-4925-b8b0-5bab2b3288a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.11.0+cu113\n"]}],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torchvision\n","import torchvision.transforms.functional as F\n","\n","print(torch.__version__)\n","plt.rcParams[\"savefig.bbox\"] = 'tight'\n","\n","\n","def show(imgs):\n","    if not isinstance(imgs, list):\n","        imgs = [imgs]\n","    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n","    for i, img in enumerate(imgs):\n","        img = img.detach()\n","        img = F.to_pil_image(img)\n","        axs[0, i].imshow(np.asarray(img))\n","        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"ejXNYAVE6xa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import Dataset,DataLoader\n","from torchvision.io import read_video,read_video_timestamps\n","from torch import nn\n","import os\n","import numpy as mp\n","import pandas as pd\n","import av\n","from torchvision.io import read_image\n","import glob\n","from time import time\n","import pickle\n","# %cd '/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/dataset/train/'\n","#%cd '/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/newdataset/train/'\n","\n","\n","tsfm=nn.Sequential(\n","    transforms.Resize(size=(180,270)),\n","\n",")\n","\n","\n","class CustomKinetics( Dataset):\n","  def __init__(self,path,csv_file,transform=tsfm,preprocessed=True):\n","    self.df=pd.read_csv(csv_file)\n","    self.path=path\n","    self.folderList=os.listdir(path)\n","    self.videos=[]\n","    print(path)\n","    #print(self.folderList)\n","    for folder in self.folderList:\n","      self.videos+=glob.glob(path+folder+'/*')\n","\n","\n","    self.transform=transform \n","    self.preprocessed=preprocessed\n","    print(len(self.folderList)) \n","    print(len(self.videos))\n","\n","  def __len__(self):\n","    return len(self.videos)\n","\n","  def __getitem__(self, idx):\n","      if torch.is_tensor(idx):\n","        idx=idx.tolist()\n","      videofile=self.videos[idx]    \n","      if self.preprocessed == True:\n","        print(videofile)\n","        with open(videofile,'rb') as f:\n","          frames=pickle.load(f)\n","        frames=torch.tensor(frames)\n","        video_name=videofile.split('/')[1]\n","        annotation=self.df.loc[self.df['youtube_id']==video_name]['label'].values[0]\n","        label=torch.zeros((400))\n","        label[label_hash[annotation]]=1\n","        frame_float=convert_image_dtype(frames, dtype=torch.float)\n","        return frame_float,label\n","\n","\n","\n","      video_name=\"_\".join(videofile.split('/')[-1].split('_')[:-2])\n","      #print(videofile)\n","      index=self.df.loc[self.df['youtube_id']==video_name]\n","      if(len(index)==0):\n","        print(\"None file : \"+video_name)\n","        return 0\n","      annotation=self.df.loc[self.df['youtube_id']==video_name]['label'].values[0]\n","      label=torch.zeros((400))\n","      # sample={'video':frame_float,'label':annotation}\n","      label[label_hash[annotation]]=1\n","\n","      try:\n","        frames,_,_=read_video(videofile)\n","      except:\n","        return None\n","    #  timestamps=read_video_timestamps(path+videofile)\n","      frames = frames.permute(0, 3, 1, 2)\n","      #print(frames.shape)\n","      if self.transform:\n","        frames=self.transform(frames)\n","      #print(frames.shape)\n","      frame_float=convert_image_dtype(frames, dtype=torch.float)\n","      #print(self.df.loc[self.df['youtube_id']==video_name]['label'])\n","      #print(frame_float)\n","      \n","\n","\n","      return frame_float,label\n","def collate_fn(batch):\n","    batch = list(filter(lambda x: x is not None, batch))\n","    return torch.utils.data.dataloader.default_collate(batch)\n","      "],"metadata":{"id":"DX_zKHzW3W5K","executionInfo":{"status":"ok","timestamp":1659951233589,"user_tz":-540,"elapsed":263,"user":{"displayName":"­김동규","userId":"13850968458248669996"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["#path=dataPath+'train/part_0/'\n","path=dataPath+'train/'\n","preprocessedPath='/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/newdataset/train/'\n","csv=dataPath+'train.csv'\n","training_data=CustomKinetics(path=preprocessedPath,csv_file=csv,preprocessed=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCExh_wQTjf3","outputId":"b0a358df-cdf2-4e83-fb60-9ba75993af8b","executionInfo":{"status":"ok","timestamp":1659951236860,"user_tz":-540,"elapsed":1972,"user":{"displayName":"­김동규","userId":"13850968458248669996"}}},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/newdataset/train/\n","242\n","92550\n"]}]},{"cell_type":"code","source":["print(len(training_data))\n","a=next(iter(training_data))"],"metadata":{"id":"Rox5JxM8VeF3","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1659951236860,"user_tz":-540,"elapsed":9,"user":{"displayName":"­김동규","userId":"13850968458248669996"}},"outputId":"ff2df214-5be0-4d30-fa84-87db516abe25"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["92550\n","/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/newdataset/train/part_0/-IOJwNb02fA\n"]},{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-cf04e2e33fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#input : 60,3,112,112\n","class semantic(nn.Module):\n","  def __init__(self):\n","    super(semantic,self).__init__()\n","    self.feature=nn.Sequential(\n","        nn.ConvTranspose2d(3,8,3,1,1),\n","        nn.MaxPool2d(2,2),\n","        nn.ConvTranspose2d(8,32,3,1,1),\n","        nn.MaxPool2d(2,2),\n","        nn.ConvTranspose2d(32,64,3,1,1),\n","        nn.MaxPool2d(2,2)\n","    )\n","    self.fc=nn.Sequential(\n","      nn.Linear(23232,32*32*4),\n","      nn.Sigmoid(),\n","      nn.Dropout(0.25),\n","      nn.Linear(32*32*4,400),\n","      nn.Sigmoid()\n","    )\n","    \n","  def forward(self,input):\n","    print(input.shape)\n","    ftr=self.feature(input)\n","    ftr=torch.flatten(ftr,1)\n","    print(ftr.shape)\n","    result=self.fc(ftr)\n","    result=torch.mean(result,0)\n","    return result\n","  #  print(ftr.shape)\n","    # n,23232\n"],"metadata":{"id":"2m5kR1SrXRr-","executionInfo":{"status":"ok","timestamp":1659950360856,"user_tz":-540,"elapsed":263,"user":{"displayName":"­김동규","userId":"13850968458248669996"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["#model=humanpose().to(device)\n","#model.eval()\n","#test_case,_=next(iter(train_dataloader))\n","#test_case=test_case.to(device)\n","#test_case=test_case.squeeze()\n","#model(test_case)"],"metadata":{"id":"tGCNBTHbjH8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/model/'\n","!dir\n","criterion=nn.CrossEntropyLoss()\n","semantic_model=semantic().to(device)\n","semantic_model.train()\n","optimizer=torch.optim.Adam(semantic_model.parameters(),lr=0.001,betas=(0.9,0.999))\n","\n","train_dataloader=DataLoader(training_data,batch_size=1,shuffle=True)\n","epochs=75\n","\n","total_len=len(training_data)\n","print(total_len)\n","for epoch in range(epochs):\n","  print(epoch)\n","  cost=0\n","  avg_cost=0\n"," # cur_time=time()\n","  for step,data in enumerate(train_dataloader):\n","      #print(data[0].dim())\n","    #  print(\"loadtime: \"+str(time()-cur_time))\n","      if(step%100==0):\n","        print(\"step\"+str(step))\n","      if(data[0].dim()==0):\n","        continue\n","    #  cur_time=time()\n","      b_x=data[0].squeeze().to(device)\n","      label=data[1].to(device)\n","      logit=semantic_model(b_x)\n","      logit=logit.unsqueeze(0)\n","      loss=criterion(logit,label)\n","      avg_cost+=loss\n","      optimizer.zero_grad() \n","      loss.backward()\n","      optimizer.step()\n","     # print(\"train time: \"+str(time()-cur_time))\n","    #  cur_time=time()\n","  print(\"cost= \"+str(avg_cost/total_len))\n","  torch.save({'model' :semantic_model.state_dict()} ,'model'+str(int(epoch))+'.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":492},"id":"-O0PiLfNXbx7","outputId":"c6ebb0c7-bd4f-443a-d2b4-7ecea9720763","executionInfo":{"status":"error","timestamp":1659950622240,"user_tz":-540,"elapsed":1243,"user":{"displayName":"­김동규","userId":"13850968458248669996"}}},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/model\n","92550\n","0\n","/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/dataset/train/\n","/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/dataset/train/\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-16751dfdad53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mavg_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m  \u001b[0;31m# cur_time=time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0;31m#print(data[0].dim())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#  print(\"loadtime: \"+str(time()-cur_time))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-0d47beff0fda>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvideofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m           \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/졸프/pose_estimation/dataset/train/part_148/b1YWPf9VZiI'"]}]},{"cell_type":"code","source":["#data_loader=torch.utils.data.DataLoader(kinetics_data,batch_size=1,shuffle=True)"],"metadata":{"id":"9DBVDOJdptMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import av\n","print(av.__version__)\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torchvision\n","import torchvision.transforms.functional as F\n","from torchvision.models.detection import keypointrcnn_resnet50_fpn\n","from torchvision.io import read_image\n","from torchvision.transforms.functional import convert_image_dtype\n","from torchvision.io import read_video,read_video_timestamps\n","from torchvision.utils import make_grid\n","from pathlib import Path\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#model = keypointrcnn_resnet50_fpn(pretrained=True).to(device).eval()\n","\n","def preprocessing(file_name):\n","  videofile=file_name\n","  frames,audio,meta=read_video(videofile)\n","  timestamps=read_video_timestamps(videofile)\n","  frames = frames.permute(0, 3, 1, 2)\n","  \n","  frame_float=convert_image_dtype(frames, dtype=torch.float)\n","  key_points=[]\n","  i=0\n","  print(len(frame_float))\n","  for frame in frame_float:\n","    if i%10==0:\n","      print(i)\n","    outputs=model([frame.to(device)])\n","    kpts = outputs[0]['keypoints']\n","    scores = outputs[0]['scores']\n","    detect_threshold = 0.87\n","    idx = torch.where(scores > detect_threshold)\n","    keypoint = kpts[idx]\n","    #print(keypoint)\n","    key_points.append(keypoint.cpu().detach().numpy())\n","    \n","    #frames[i]=draw_keypoints(frames[i],keypoint,colors='blue',radius=3)\n","    #show(frames[i])\n","    i+=1\n","    return key_points\n","\n","  \n"],"metadata":{"id":"hFGdpzC15h5A"},"execution_count":null,"outputs":[]}]}